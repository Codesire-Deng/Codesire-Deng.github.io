<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic%7CFira+Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"codesire-deng.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="参考资料：  《CUDA 编程 基础与实践》樊哲勇 CUDA Toolkit Documentation  获得 GPU 加速的关键总结必要条件 数据传输比例较小 核函数的算术强度较高 核函数中定义的线程数目较多  提高性能的技巧 减少主机与设备之间的数据传输 提高核函数的算术强度 增大核函数的并行规模">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA 学习笔记">
<meta property="og:url" content="https://codesire-deng.github.io/2021/08/05/cuda/index.html">
<meta property="og:site_name" content="等疾风">
<meta property="og:description" content="参考资料：  《CUDA 编程 基础与实践》樊哲勇 CUDA Toolkit Documentation  获得 GPU 加速的关键总结必要条件 数据传输比例较小 核函数的算术强度较高 核函数中定义的线程数目较多  提高性能的技巧 减少主机与设备之间的数据传输 提高核函数的算术强度 增大核函数的并行规模">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-08-05T15:50:25.000Z">
<meta property="article:modified_time" content="2021-08-15T08:12:13.883Z">
<meta property="article:author" content="等疾风">
<meta property="article:tag" content="GPGPU">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://codesire-deng.github.io/2021/08/05/cuda/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://codesire-deng.github.io/2021/08/05/cuda/","path":"2021/08/05/cuda/","title":"CUDA 学习笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CUDA 学习笔记 | 等疾风</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="等疾风" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">等疾风</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">正在捣鼓协程</p>
      <img class="custom-logo-image" src="/uploads/custom-logo4.png" alt="等疾风">
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-log"><a href="/log/" rel="section"><i class="fa fa-sync-alt fa-fw"></i>Log</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%8E%B7%E5%BE%97-GPU-%E5%8A%A0%E9%80%9F%E7%9A%84%E5%85%B3%E9%94%AE"><span class="nav-number">1.</span> <span class="nav-text">获得 GPU 加速的关键</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.1.</span> <span class="nav-text">总结</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6"><span class="nav-number">1.1.1.</span> <span class="nav-text">必要条件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E6%8A%80%E5%B7%A7"><span class="nav-number">1.1.2.</span> <span class="nav-text">提高性能的技巧</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SM-%E6%B5%81%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">2.</span> <span class="nav-text">SM 流多处理器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SM-%E7%9A%84%E6%9E%84%E6%88%90"><span class="nav-number">2.1.</span> <span class="nav-text">SM 的构成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SM-%E7%9A%84%E5%8D%A0%E6%9C%89%E7%8E%87"><span class="nav-number">2.2.</span> <span class="nav-text">SM 的占有率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E6%97%B6API%E6%9F%A5%E8%AF%A2%E8%AE%BE%E5%A4%87"><span class="nav-number">2.3.</span> <span class="nav-text">运行时API查询设备</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">全局内存的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E8%AE%BF%E9%97%AE"><span class="nav-number">3.1.</span> <span class="nav-text">合并访问</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E4%BC%98%E5%85%88%E4%BA%8E%E5%8F%AA%E8%AF%BB"><span class="nav-number">3.2.</span> <span class="nav-text">写优先于只读</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-number">4.</span> <span class="nav-text">共享内存的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="nav-number">4.1.</span> <span class="nav-text">动态共享内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%81%BF%E5%85%8D%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84bank%E5%86%B2%E7%AA%81"><span class="nav-number">4.2.</span> <span class="nav-text">避免共享内存的bank冲突</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0"><span class="nav-number">5.</span> <span class="nav-text">原子函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%89%B9%E6%80%A7"><span class="nav-number">5.1.</span> <span class="nav-text">特性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E6%80%A7%E7%B2%92%E5%BA%A6"><span class="nav-number">5.2.</span> <span class="nav-text">原子性粒度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0%E9%80%9F%E6%9F%A5"><span class="nav-number">5.3.</span> <span class="nav-text">原子函数速查</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E4%B8%8E%E5%8D%8F%E4%BD%9C%E7%BB%84"><span class="nav-number">6.</span> <span class="nav-text">线程束与协作组</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SIMT"><span class="nav-number">6.1.</span> <span class="nav-text">SIMT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E5%86%85%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5"><span class="nav-number">6.2.</span> <span class="nav-text">线程束内的线程同步</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9D%9F%E5%86%85%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%87%BD%E6%95%B0"><span class="nav-number">6.3.</span> <span class="nav-text">更多线程束内的基本函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E8%A1%A8%E5%86%B3"><span class="nav-number">6.3.1.</span> <span class="nav-text">线程束表决</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C"><span class="nav-number">6.3.2.</span> <span class="nav-text">线程束洗牌</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%8F%E4%BD%9C%E7%BB%84"><span class="nav-number">6.4.</span> <span class="nav-text">协作组</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E5%9D%97%E7%BA%A7%E5%88%AB%E7%9A%84%E5%8D%8F%E4%BD%9C%E7%BB%84"><span class="nav-number">6.4.1.</span> <span class="nav-text">线程块级别的协作组</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%8D%E6%AC%A1%E4%BC%98%E5%8C%96%E6%95%B0%E7%BB%84%E5%BD%92%E7%BA%A6"><span class="nav-number">6.5.</span> <span class="nav-text">再次优化数组归约</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E6%B5%81"><span class="nav-number">7.</span> <span class="nav-text">CUDA 流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%87%BD%E6%95%B0%E5%A4%96%E9%83%A8%E7%9A%84%E5%B9%B6%E8%A1%8C"><span class="nav-number">7.1.</span> <span class="nav-text">核函数外部的并行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-CUDA-%E6%B5%81"><span class="nav-number">7.2.</span> <span class="nav-text">使用 CUDA 流</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%87%E4%BB%A4%E9%80%9F%E6%9F%A5"><span class="nav-number">8.</span> <span class="nav-text">指令速查</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E8%AF%91%E5%99%A8%E9%80%89%E9%A1%B9"><span class="nav-number">8.1.</span> <span class="nav-text">编译器选项</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%AE%E9%A5%B0%E7%AC%A6"><span class="nav-number">8.2.</span> <span class="nav-text">修饰符</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81"><span class="nav-number">9.</span> <span class="nav-text">常用代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CMake%E6%A8%A1%E6%9D%BF"><span class="nav-number">9.1.</span> <span class="nav-text">CMake模板</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8A%A5%E9%94%99%E3%80%81%E8%AE%A1%E6%97%B6%E5%B7%A5%E5%85%B7"><span class="nav-number">9.2.</span> <span class="nav-text">报错、计时工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B2%BE%E5%BA%A6%E6%8E%A7%E5%88%B6%E6%A8%A1%E6%9D%BF"><span class="nav-number">9.3.</span> <span class="nav-text">精度控制模板</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="等疾风"
      src="/uploads/blogAvatar_s.jpg">
  <p class="site-author-name" itemprop="name">等疾风</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">38</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Codesire-Deng" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Codesire-Deng" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:oi_dzf@qq.com" title="E-Mail → mailto:oi_dzf@qq.com" rel="noopener" target="_blank"><i class="fas fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=513374673&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;513374673&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener" target="_blank"><i class="fab fa-qq fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/35186937" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;35186937" rel="noopener" target="_blank"><i class="fa-brands fa-bilibili fa-fw"></i></a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://codesire-deng.github.io/2021/08/05/cuda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/blogAvatar_s.jpg">
      <meta itemprop="name" content="等疾风">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="等疾风">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CUDA 学习笔记 | 等疾风">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CUDA 学习笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-08-05 23:50:25" itemprop="dateCreated datePublished" datetime="2021-08-05T23:50:25+08:00">2021-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2021-08-15 16:12:13" itemprop="dateModified" datetime="2021-08-15T16:12:13+08:00">2021-08-15</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>参考资料：</p>
<ul>
<li>《CUDA 编程 基础与实践》樊哲勇</li>
<li><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/index.html">CUDA Toolkit Documentation</a></li>
</ul>
<h2 id="获得-GPU-加速的关键"><a href="#获得-GPU-加速的关键" class="headerlink" title="获得 GPU 加速的关键"></a>获得 GPU 加速的关键</h2><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h4 id="必要条件"><a href="#必要条件" class="headerlink" title="必要条件"></a>必要条件</h4><ol>
<li>数据传输比例较小</li>
<li>核函数的算术强度较高</li>
<li>核函数中定义的线程数目较多</li>
</ol>
<h4 id="提高性能的技巧"><a href="#提高性能的技巧" class="headerlink" title="提高性能的技巧"></a>提高性能的技巧</h4><ol>
<li>减少主机与设备之间的数据传输</li>
<li>提高核函数的算术强度</li>
<li>增大核函数的并行规模</li>
</ol>
<span id="more"></span>

<h2 id="SM-流多处理器"><a href="#SM-流多处理器" class="headerlink" title="SM 流多处理器"></a>SM 流多处理器</h2><p>官方有时简称 Multiprocessor</p>
<h3 id="SM-的构成"><a href="#SM-的构成" class="headerlink" title="SM 的构成"></a>SM 的构成</h3><ol>
<li>寄存器</li>
<li>共享内存</li>
<li>常量内存的缓存</li>
<li>纹理和表面内存的缓存</li>
<li>L1 缓存</li>
<li>（常见4个）线程束调度器</li>
<li>执行核心：INT32, FP32, FP64, 单精度浮点数超于函数的特殊函数单元(special function unit, SFUs), 混合精度的张量核心(tensor cores)</li>
</ol>
<h3 id="SM-的占有率"><a href="#SM-的占有率" class="headerlink" title="SM 的占有率"></a>SM 的占有率</h3><p>当并行规模较小，有些 SM 占有率为零，导致程序性能低下。当并行规模足够大时，也有可能得到非 100% 的占有率。</p>
<p>考虑指标（查询官方文档 CUDA_Occupancy_Calculator.xls 的图灵架构）：</p>
<ol>
<li>一个 SM 最多拥有线程块个数$\ N_b &#x3D; 16$。</li>
<li>一个 SM 最多拥有的线程个数$\ N_t &#x3D; 1536$。</li>
<li>线程块大小最大为$\ 1024$。</li>
</ol>
<p>当并行规模足够大（核函数配置的总线程数足够多），需要分几种情况讨论 SM 的理论占有率：</p>
<ol>
<li>寄存器核共享内存使用量很少。SM 的占有率完全由线程块大小决定。首先，由于线程束大小是 32，线程块大小最好是 32 的倍数。其次，线程块大小不能小于$\ N_t&#x2F;N_b$​，才可能利用最大线程数量。因此，96 的线程块大小就能获得 100% 的占有率。类似的，128 的线程块大小在开普勒架构下能获得满占有率。（我选择 128）</li>
<li>寄存器带来占有率瓶颈。一个 SM 最多有 65536（64K）个寄存器。如果令线程数最大化（1536），那么平均一个线程可用 42.7 个寄存器。当每个线程所用的寄存器个数大于 42 时，SM 的占有率将低于 50%。</li>
<li>有限的共享内存对占有率的约束。一个 SM 拥有 65536 字节共享内存。如果线程块大小为 128，且SM 是线程满载（1536），要令占有率为 100%，则网格大小为 12，一个线程块最多有 5461 字节的共享内存。</li>
</ol>
<h3 id="运行时API查询设备"><a href="#运行时API查询设备" class="headerlink" title="运行时API查询设备"></a>运行时API查询设备</h3><p>参考<code>deviceQuery.cpp</code></p>
<h2 id="全局内存的合理使用"><a href="#全局内存的合理使用" class="headerlink" title="全局内存的合理使用"></a>全局内存的合理使用</h2><h3 id="合并访问"><a href="#合并访问" class="headerlink" title="合并访问"></a>合并访问</h3><p>全局内存具有最高的延迟，所以配置有缓存，每次 Cache Miss 默认读取 32 字节。由于缓存命中问题，需要提高内存访问的合并度，从而提高效率。简单起见，只考虑全局内存到 L2 缓存。可以定义合并度(degree of coalescing) 为<strong>一个线程束</strong>请求的字节数除以实际数据传输处理的字节数。合并度体现了显存带宽的利用率。</p>
<p>CUDA 运行时 API 函数分配的内存的首地址至少是256字节的整数倍。</p>
<p>只要确保每当线程束读取一次内存后，该内存对应的32字节范围都被当前线程束利用，则合并度就是100%。</p>
<p>对于一个线程束访问同一个全局内存地址的 4 字节，属于广播式的非合并访问（因为只用了 4 字节而非 32 字节，合并度为 12.5%）。如果内存只读，那么适合采用常量内存。</p>
<h3 id="写优先于只读"><a href="#写优先于只读" class="headerlink" title="写优先于只读"></a>写优先于只读</h3><p>有时候合并写入与合并读取无法兼顾，例如矩阵转置。此时应当优先保证写入是合并的。</p>
<p>这是因为从帕斯卡架构开始，若编译器判定一个全局内存变量在整个核函数的范围内都<strong>只读</strong>，则会自动用函数<code>__ldg()</code>读取全局内存，附带缓存效果，缓解非合并访问的影响。但对于全局内存的写入，没有类似的优化手段。</p>
<h2 id="共享内存的合理使用"><a href="#共享内存的合理使用" class="headerlink" title="共享内存的合理使用"></a>共享内存的合理使用</h2><p>在核函数内，使用<code>__shared__</code>修饰的变量（数组）将使用共享内存。同一线程块使用同一个共享内存副本，而不同线程块的共享内存是互相独立的，不可见的。</p>
<p>利用共享内存，可以消除一些无法兼顾读写合并的全局内存访问，例如数组归约，先将要读取的数据从全局内存拷贝至共享内存（然后<code>__syncthreads()</code>同步一下），可以带来细微的性能提升。</p>
<p>对共享内存的访问越频繁，性能提升越明显。</p>
<h3 id="动态共享内存"><a href="#动态共享内存" class="headerlink" title="动态共享内存"></a>动态共享内存</h3><p>共享内存大小可以在核函数的执行配置中指定：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;&lt;&lt;grid_size, block_size, <span class="built_in">sizeof</span>(real) * block_size&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

<p>同时要修改共享内存变量的声明方式</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// before</span></span><br><span class="line">__shared__ real a[<span class="number">128</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// after</span></span><br><span class="line"><span class="keyword">extern</span> __shared__ real a[];</span><br></pre></td></tr></table></figure>

<p>动态和静态的声明方式在性能上几乎没有差别。</p>
<h3 id="避免共享内存的bank冲突"><a href="#避免共享内存的bank冲突" class="headerlink" title="避免共享内存的bank冲突"></a>避免共享内存的bank冲突</h3><p>共享内存在物理上被分为 32 个（恰好是线程束大小）个 bank，多个线程同时访问同一个 bank 会导致冲突；多个线程同时访问不同的 bank 能取得更高的性能。</p>
<p>除了开普勒架构（8 字节）外，每 4 个字节被划分到一个 bank。例如 <code>0000</code> 属于 bank0，<code>0004</code> 属于 bank1 …… <code>0128</code> 属于 bank0。可以看出，每个 bank 的相邻层的地址相差 128。</p>
<p>一个线程束试图同时访问同一个 bank 中的 n 层数据将导致 n 次 内存事务(memory transaction)。亦称为 n 路 bank 冲突。n 很大的 bank 冲突是要尽量避免的。</p>
<p>在矩阵转置中，写入共享内存时易产生 bank 冲突，可以通过修改数组大小解决。</p>
<p>记得双精度浮点数占 8 字节。</p>
<h2 id="原子函数"><a href="#原子函数" class="headerlink" title="原子函数"></a>原子函数</h2><p>例如在数组归约（加法）中，要令GPU完成求和，需要使用原子操作。</p>
<h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>原子函数在全局内存和共享内存上体现原子性。</p>
<p>原子函数不依赖内存栅栏，不需要线程同步或顺序约束（参考<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions">官方文档</a>）。</p>
<p>原子函数只能用于设备函数。</p>
<h3 id="原子性粒度"><a href="#原子性粒度" class="headerlink" title="原子性粒度"></a>原子性粒度</h3><p>系统原子性：在任意 CPU 和 GPU 的任意线程上保持原子性。函数名有后缀<code>_system</code>，如<code>atomicAdd_system</code>。</p>
<p>设备原子性：在当前 GPU 的任意线程上保持原子性。函数名无附加后缀。</p>
<p>线程块原子性：在当前 GPU 的同一线程块中的任意线程上保持原子性。函数名有后缀<code>_block</code>，如<code>atomicAdd_block</code>。</p>
<h3 id="原子函数速查"><a href="#原子函数速查" class="headerlink" title="原子函数速查"></a>原子函数速查</h3><p><strong>注意：所有的函数都返回旧值</strong></p>
<p>支持的类型可参考书第 92 页。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// T in &#123;int, unsigned int, unsigned long long int&#125;</span></span><br><span class="line"><span class="keyword">using</span> UI = <span class="type">unsigned</span> <span class="type">int</span>;</span><br><span class="line"><span class="function">T <span class="title">atomicAdd</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 加法，支持浮点</span></span><br><span class="line"><span class="function">T <span class="title">atomicSub</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 减法，支持浮点</span></span><br><span class="line"><span class="function">T <span class="title">atomicExch</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// new = val，支持float</span></span><br><span class="line"><span class="function">T <span class="title">atomicMin</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 最小值</span></span><br><span class="line"><span class="function">T <span class="title">atomicMax</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 最大值</span></span><br><span class="line"><span class="function">UI <span class="title">atomicInc</span><span class="params">(UI *address, UI val)</span></span>; <span class="comment">// new = (old &gt;= val) ? 0 : (old+1)</span></span><br><span class="line"><span class="function">UI <span class="title">atomicDec</span><span class="params">(UI *address, UI val)</span></span>; <span class="comment">// new = ((old == 0) || (old &gt; val)) ? val : (old-1)</span></span><br><span class="line"><span class="function">T <span class="title">atomicAnd</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 按位与</span></span><br><span class="line"><span class="function">T <span class="title">atomicOr</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 按位或</span></span><br><span class="line"><span class="function">T <span class="title">atomicXor</span><span class="params">(T *address, T val)</span></span>; <span class="comment">// 按位异或</span></span><br><span class="line"><span class="function">T <span class="title">atomicCAS</span><span class="params">(T *address, T compare, T val)</span></span>; <span class="comment">// new = old == compare ? val : old。支持unsigned short int</span></span><br></pre></td></tr></table></figure>

<h2 id="线程束与协作组"><a href="#线程束与协作组" class="headerlink" title="线程束与协作组"></a>线程束与协作组</h2><h3 id="SIMT"><a href="#SIMT" class="headerlink" title="SIMT"></a>SIMT</h3><p>单指令-多线程（single instruction multiple thread, SIMT）：不同线程共享同一个 PC。SIMT 的通病是分支发散（branch divergence），所有的分支会产生串行的时间开销。</p>
<p>在伏特架构之前，一个线程束共享一个 PC。不同线程束之间没有分支发散问题。</p>
<p>从伏特架构开始，引入了独立线程调度（independent thread scheduling）机制。每个线程有自己的 PC，使得需要用户自己控制线程束内的同步。另一个代价是每个线程需要用两个寄存器来做 PC。如果旧代码出现线程束内不安全的问题，可以指定虚拟架构为低于伏特架构的计算能力。</p>
<h3 id="线程束内的线程同步"><a href="#线程束内的线程同步" class="headerlink" title="线程束内的线程同步"></a>线程束内的线程同步</h3><p><code>__syncwarp()</code>比线程块同步函数<code>__syncthreads()</code>更加廉价。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 函数原型</span></span><br><span class="line"><span class="type">void</span> __syncwarp(<span class="type">unsigned</span> mask = <span class="number">0xffffffff</span>);</span><br></pre></td></tr></table></figure>

<p>其中掩码表示参与同步的线程，默认 32 个线程全部参与。</p>
<p>在分治时，当问题规模缩小到一个线程束内，可以不使用<code>__syncthreads</code>而用<code>__syncwarp</code>。</p>
<h3 id="更多线程束内的基本函数"><a href="#更多线程束内的基本函数" class="headerlink" title="更多线程束内的基本函数"></a>更多线程束内的基本函数</h3><p><strong>注意：若当前线程不参与，则函数的返回值是无定义的。</strong></p>
<p>线程束表决函数（warp vote functions）</p>
<p>线程束匹配函数（warp match functions）<em>待续</em></p>
<p>线程束洗牌函数（warp shuffle functions）</p>
<p>线程束矩阵函数（warp matrix functions）<em>待续</em></p>
<h4 id="线程束表决"><a href="#线程束表决" class="headerlink" title="线程束表决"></a>线程束表决</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> __ballot_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="comment">// 若当前线程参与，则同步表决下一次参与意愿（当 predicate 非零，则令返回值对应位置 1， 否则置 0。）。相当于从旧掩码表决出一个新掩码。</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> __all_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="comment">// 若当前线程参与，则同步投票，一票否决，返回投票是否通过。所有参与线程都同意才通过。</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> __any_sync(<span class="type">unsigned</span> mask, <span class="type">int</span> predicate);</span><br><span class="line"><span class="comment">// 若当前线程参与，则同步投票，一票通过，返回投票是否通过。</span></span><br></pre></td></tr></table></figure>

<h4 id="线程束洗牌"><a href="#线程束洗牌" class="headerlink" title="线程束洗牌"></a>线程束洗牌</h4><p>定义“束内指标” <code>int lane_id = threadIdx.x % w</code>。</p>
<p><code>w</code> 是逻辑线程束大小，只能取 2、4、8、16、32 中的一个。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">T __shfl_sync(<span class="type">unsigned</span> mask, T v, <span class="type">int</span> srcLane, <span class="type">int</span> w=warpSize);</span><br><span class="line"><span class="comment">// 参与线程返回标号为 srcLane 的变量 v 的值。这是一种广播式数据交换。 </span></span><br><span class="line"></span><br><span class="line">T __shfl_up_sync(<span class="type">unsigned</span> mask, T v, <span class="type">unsigned</span> d, <span class="type">int</span> w=warpSize);</span><br><span class="line"><span class="comment">// 标号为 t 的参与线程返回标号为 t - d 的线程中的 v 的值；若 t - d &lt; 0 则返回原来的 v。相当于数据向上平移。</span></span><br><span class="line"></span><br><span class="line">T __shfl_down_sync(<span class="type">unsigned</span> mask, T v, <span class="type">unsigned</span> d, <span class="type">int</span> w=warpSize);</span><br><span class="line"><span class="comment">// 标号为 t 的参与线程返回标号为 t + d 的线程中的 v 的值；若 t + d &gt;= w 则返回原来的 v。相当于数据向下平移。</span></span><br><span class="line"></span><br><span class="line">T __shfl_xor_sync(<span class="type">unsigned</span> mask, T v, <span class="type">int</span> laneMask, <span class="type">int</span> w=warpSize);</span><br><span class="line"><span class="comment">// 标号为 t 的参与线程返回标号为 t ^ laneMask 的线程中的 v 的值；相当于对应的两个线程交换数据。</span></span><br></pre></td></tr></table></figure>

<p>使用线程束洗牌优化数组归约：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">constexpr</span> <span class="type">unsigned</span> <span class="type">int</span> FULL_MASK = <span class="number">0xffffffff</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">reduce_shfl</span><span class="params">(<span class="type">const</span> real *d_x, real *d_y, <span class="type">const</span> <span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = bid * blockDim.x + tid;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ real s_y[];</span><br><span class="line">    s_y[tid] = (n &lt; N ? d_x[n] : <span class="number">0.0</span>);</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x &gt;&gt; <span class="number">1</span>; offset &gt;= <span class="number">32</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset) &#123;</span><br><span class="line">            s_y[tid] += s_y[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real y = s_y[tid]; <span class="comment">// 寄存器优化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = <span class="number">16</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        y +=  __shfl_down_sync(FULL_MASK, y, offset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">atomicAdd</span>(d_y, y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="协作组"><a href="#协作组" class="headerlink" title="协作组"></a>协作组</h3><p>协作组（cooperative groups）可以看作线程块和线程束同步机制的推广。范围涵盖线程块内部，线程块之间（网格级）及设备之间的同步与协作。</p>
<p>引入头文件和命名空间</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cooperative_groups.h&gt;</span></span></span><br><span class="line"><span class="keyword">namespace</span> cg = cooperative_groups; <span class="comment">// 仅供参考</span></span><br></pre></td></tr></table></figure>

<h4 id="线程块级别的协作组"><a href="#线程块级别的协作组" class="headerlink" title="线程块级别的协作组"></a>线程块级别的协作组</h4><p>基本类型<code>thread_group</code>。有如下成员：</p>
<ol>
<li><code>void sync()</code> 同步组内所有线程</li>
<li><code>unsigned size()</code> 返回组内总的线程数目</li>
<li><code>unsigned thread_rank()</code> 返回当前线程的组内标号</li>
<li><code>bool is_valid()</code> 检查定义的组是否违反 CUDA 的任何限制</li>
</ol>
<p>导出类型<code>thread_block</code>，额外函数：</p>
<ol>
<li><code>dim3 group_index()</code> 返回当前线程的线程块指标，相当于 blockIdx</li>
<li><code>dim3 thread_index()</code> 相当于 threadIdx</li>
</ol>
<p>于是可以抽象出当前线程块：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">thread_block g = <span class="built_in">this_thread_block</span>();</span><br><span class="line">g.<span class="built_in">sync</span>(); <span class="comment">// 等价于 __syncthreads()</span></span><br></pre></td></tr></table></figure>

<p>可以将 <code>thread_block</code> 进行多次分割（但一组线程的数量只能是 2 的幂次）：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread_group g32 = <span class="built_in">tiled_partition</span>(<span class="built_in">this_thread_block</span>(), <span class="number">32</span>); <span class="comment">// 相当于线程束</span></span><br><span class="line">thread_group g4 = <span class="built_in">tiled_partition</span>(g32, <span class="number">4</span>); <span class="comment">// 再次分割</span></span><br><span class="line"><span class="comment">// ---------- 模板化版本 ----------</span></span><br><span class="line">thread_block_tile&lt;<span class="number">32</span>&gt; g32 = <span class="built_in">tiled_partition</span>&lt;<span class="number">32</span>&gt;(<span class="built_in">this_thread_block</span>());</span><br></pre></td></tr></table></figure>

<p>这样的“线程块片”可以模仿线程束的一些行为，比如</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> __ballot_sync(<span class="type">int</span> predicate);</span><br><span class="line"><span class="type">int</span> __all_sync(<span class="type">int</span> predicate);</span><br><span class="line"><span class="type">int</span> __any_sync(<span class="type">int</span> predicate);</span><br><span class="line">T __shfl_sync(T v, <span class="type">int</span> srcLane);</span><br><span class="line">T __shfl_up_sync(T v, <span class="type">unsigned</span> d);</span><br><span class="line">T __shfl_down_sync(T v, <span class="type">unsigned</span> d);</span><br><span class="line">T __shfl_xor_sync(T v, <span class="type">int</span> laneMask);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 相对线程束的不同点：1. 不允许掩码，所有线程必须参与 2. 洗牌函数不再需要宽度参数，宽度由线程块片大小确定</span></span><br></pre></td></tr></table></figure>

<h3 id="再次优化数组归约"><a href="#再次优化数组归约" class="headerlink" title="再次优化数组归约"></a>再次优化数组归约</h3><p>这次我们采用的技巧有：</p>
<ol>
<li>使用静态全局内存</li>
<li>调用两次核函数，舍弃原子加法函数（这会提高精确度）</li>
<li>提高线程利用率（在规约之前进行小部分求和）</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;real.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;widgets.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">unsigned</span> <span class="type">int</span> FULL_MASK = <span class="number">0xffffffff</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">reduce_cp</span><span class="params">(<span class="type">const</span> real *d_x, real *d_y, <span class="type">const</span> <span class="type">int</span> N)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ real s_y[];</span><br><span class="line"></span><br><span class="line">    real y = <span class="number">0.0</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> stride = blockDim.x * gridDim.x; <span class="comment">// 以网格大小为跨度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = bid * blockDim.x + tid; n &lt; N; n += stride) &#123;</span><br><span class="line">        y += d_x[n]; <span class="comment">// 确保一个网格能覆盖所有数据</span></span><br><span class="line">    &#125;</span><br><span class="line">    s_y[tid] = y;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程块内，跨线程束折半归约</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x &gt;&gt; <span class="number">1</span>; offset &gt;= <span class="number">32</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset) &#123;</span><br><span class="line">            s_y[tid] += s_y[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    y = s_y[tid];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = <span class="number">16</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        y += __shfl_down_sync(FULL_MASK, y, offset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) &#123;</span><br><span class="line">        d_y[bid] = y; <span class="comment">// 返回线程块结果</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int</span> N = <span class="number">1e8</span>;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int</span> GRID_SIZE = <span class="number">10240</span>;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">int</span> BLOCK_SIZE = <span class="number">128</span>;</span><br><span class="line">__device__ real d_input[N];</span><br><span class="line">__device__ real d_output[GRID_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="function">real <span class="title">reduce</span><span class="params">(<span class="type">const</span> real *d_x)</span> </span>&#123;</span><br><span class="line">    real *d_y;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetSymbolAddress</span>((<span class="type">void</span>**)&amp;d_y, d_output));</span><br><span class="line">    <span class="keyword">constexpr</span> <span class="type">int</span> shared_size = <span class="built_in">sizeof</span>(real) * BLOCK_SIZE;</span><br><span class="line">    reduce_cp&lt;&lt;&lt;GRID_SIZE, BLOCK_SIZE, shared_size&gt;&gt;&gt;(d_x, d_y, N);</span><br><span class="line">    reduce_cp&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1024</span>, <span class="built_in">sizeof</span>(real) * <span class="number">1024</span>&gt;&gt;&gt;(d_y, d_y, GRID_SIZE);</span><br><span class="line"></span><br><span class="line">    real h_y[<span class="number">1</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, <span class="built_in">sizeof</span>(real), cudaMemcpyDeviceToHost));</span><br><span class="line">    <span class="comment">// CHECK(cudaMemcpyFromSymbol(h_y, d_output, sizeof(real)));</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> h_y[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line">    <span class="type">static</span> real input[N];</span><br><span class="line">    std::<span class="built_in">fill_n</span>(input, N, <span class="number">1.23f</span>);</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyToSymbol</span>(d_input, input, N * <span class="built_in">sizeof</span>(real)));</span><br><span class="line">    real *d_x;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetSymbolAddress</span>((<span class="type">void</span>**)&amp;d_x, d_input));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%f\n&quot;</span>, <span class="built_in">reduce</span>(d_x));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 运行结果：</span></span><br><span class="line"><span class="comment">// 123000064.000000</span></span><br><span class="line"><span class="comment">// 对比 CPU 裸归约方法的加速比：67</span></span><br></pre></td></tr></table></figure>

<h2 id="CUDA-流"><a href="#CUDA-流" class="headerlink" title="CUDA 流"></a>CUDA 流</h2><h3 id="核函数外部的并行"><a href="#核函数外部的并行" class="headerlink" title="核函数外部的并行"></a>核函数外部的并行</h3><p>主要有以下情形：</p>
<ol>
<li>核函数计算与数据传输之间的并行</li>
<li>主机计算与数据传输之间的并行</li>
<li>不同的数据传输之间的并行</li>
<li>核函数计算与主机计算之间的并行</li>
<li>不同核函数之间的并行</li>
</ol>
<p>若两个任务的运行时间相近，则尽量令他们并行。反之，则并行和串行的性能差距不大。</p>
<p>使用 CUDA 流的主要目的是尽量取得核函数外部的并行能力。</p>
<h3 id="使用-CUDA-流"><a href="#使用-CUDA-流" class="headerlink" title="使用 CUDA 流"></a>使用 CUDA 流</h3><p>CUDA 流的使用相对简单，只要记住一些规则就好。</p>
<ol>
<li><p>CUDA 程序有一个默认流。若 API 不需要指定流句柄，可推测它用于默认流。</p>
</li>
<li><p>创建、销毁 CUDA 流</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cudaStream_t stream[<span class="number">5</span>];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;s : stream) &#123;</span><br><span class="line">    <span class="built_in">cudaStreamCreate</span>(&amp;s); <span class="comment">// 创建流，获得句柄</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;s : stream) &#123;</span><br><span class="line">    <span class="built_in">cudaStreamDestroy</span>(s); <span class="comment">// 销毁流，句柄不抹除</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>检测 CUDA 流是否空闲 </p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamSynchronize</span><span class="params">(cudaStream_t stream)</span></span>; <span class="comment">// 阻塞主机，直到 CUDA 流完成所有操作</span></span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamQuery</span><span class="params">(cudaStream_t stream)</span></span>; <span class="comment">// 返回 cudaSuccess（已完成）/ cudaErrorNotReady（未完成）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>cudaMemcpy</code> 会阻塞主机。但是核函数的调用总是异步的。应该尽量早地调用核函数，随后再进行主机的计算任务。</p>
</li>
<li><p>在核函数配置中指派 CUDA 流：</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_kernel&lt;&lt;&lt;N_grid, N_block, N_shared, stream_id&gt;&gt;&gt;(...); <span class="comment">// 四个模板参数必须齐全</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>异步的数据传输需要：</p>
<ol>
<li>使用 <code>cudaMemcpyAsync</code> 函数。</li>
<li>涉及的主机内存必须是不可分页的，否则 API 将会退化为同步版本。</li>
</ol>
<p> 异步传输的过程将由 GPU 的 DMA（direct memory access）接管。</p>
</li>
<li><p>可以用 CUDA 运行时 API 来申请不可分页的内存（non-pageable memory），又称固定内存（pinned memory）。不可分页意味着操作系统无权修改虚拟地址所对应的物理地址。</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMallocHost</span><span class="params">(<span class="type">void</span> **ptr, <span class="type">size_t</span> size)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaHostAlloc</span><span class="params">(<span class="type">void</span> **ptr, <span class="type">size_t</span> size, <span class="type">size_t</span> flags)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaFreeHost</span><span class="params">(<span class="type">void</span> *ptr)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>良好的 CUDA 流指派会从流水线重叠中获得并行加速。但是 CUDA 流是有启动开销，且硬件环境有限，过多的 CUDA 流会拉低性能。</p>
</li>
</ol>
<h2 id="指令速查"><a href="#指令速查" class="headerlink" title="指令速查"></a>指令速查</h2><h3 id="编译器选项"><a href="#编译器选项" class="headerlink" title="编译器选项"></a>编译器选项</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--ptxas-options=-v <span class="comment"># 报道每个核函数的寄存器使用数量</span></span><br><span class="line">--maxrregcount= <span class="comment"># 限制所有核函数的寄存器使用量</span></span><br></pre></td></tr></table></figure>

<h3 id="修饰符"><a href="#修饰符" class="headerlink" title="修饰符"></a>修饰符</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="comment"># 核函数修饰符</span></span><br><span class="line">__device__ <span class="comment"># 设备函数、变量修饰符</span></span><br><span class="line">__host__ <span class="comment"># 主机函数修饰符，一般只与__device__同时出现</span></span><br><span class="line">__noinline__ <span class="comment"># 建议函数非内联</span></span><br><span class="line">__forceinline__ <span class="comment"># 建议函数内联</span></span><br><span class="line">__launch_bounds__() <span class="comment"># 修饰核函数，限制寄存器使用量</span></span><br><span class="line">__shared__ <span class="comment"># 修饰全局变量，使它成为共享内存</span></span><br><span class="line">__managed__ <span class="comment"># 修饰全局变量，使它成为统一内存，必须与__device__同时出现</span></span><br></pre></td></tr></table></figure>

<h2 id="常用代码"><a href="#常用代码" class="headerlink" title="常用代码"></a>常用代码</h2><h3 id="CMake模板"><a href="#CMake模板" class="headerlink" title="CMake模板"></a>CMake模板</h3><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2021/08/02</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(hello LANGUAGES CUDA VERSION <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">option</span>(USE_DOUBLE <span class="string">&quot;Use real as double, otherwise float&quot;</span> <span class="keyword">OFF</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">find_package</span>(CUDAToolkit REQUIRED)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set(CMAKE_CUDA_COMPILER_ID NVIDIA)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set(ENV&#123;PATH&#125; &quot;C:/Program\ Files\ (x86)/Microsoft\ Visual\ Studio/2019/Community/VC/Tools/MSVC/14.29.30037/bin/Hostx64/x64:$ENV&#123;PATH&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># report registers used in each core function</span></span><br><span class="line"><span class="keyword">add_compile_options</span>(--ptxas-options=-v)</span><br><span class="line"></span><br><span class="line"><span class="keyword">include_directories</span>(./<span class="keyword">include</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_executable</span>(hello main.cu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute capability, see https://developer.nvidia.com/zh-cn/cuda-gpus#compute</span></span><br><span class="line"><span class="keyword">set_property</span>(<span class="keyword">TARGET</span> hello PROPERTY CUDA_ARCHITECTURES <span class="number">86</span>)</span><br><span class="line"><span class="comment"># set_property(TARGET hello PROPERTY CUDA_ARCHITECTURES 75)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># install(TARGETS hello DESTINATION .)</span></span><br></pre></td></tr></table></figure>

<h3 id="报错、计时工具"><a href="#报错、计时工具" class="headerlink" title="报错、计时工具"></a>报错、计时工具</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// widgets.hpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK(callee)                                            \</span></span><br><span class="line"><span class="meta">    do &#123;                                                         \</span></span><br><span class="line"><span class="meta">        const cudaError_t err = callee;                          \</span></span><br><span class="line"><span class="meta">        <span class="keyword">if</span> (err == cudaSuccess) break;                           \</span></span><br><span class="line"><span class="meta">        printf(<span class="string">&quot;CUDA error at %s(%d)\n&quot;</span>, __FILE__, __LINE__);    \</span></span><br><span class="line"><span class="meta">        printf(<span class="string">&quot;    Function:   %s\n&quot;</span>, __FUNCTION__);            \</span></span><br><span class="line"><span class="meta">        printf(<span class="string">&quot;    Error code: %d\n&quot;</span>, err);                     \</span></span><br><span class="line"><span class="meta">        printf(<span class="string">&quot;    Error hint: %s\n&quot;</span>, cudaGetErrorString(err)); \</span></span><br><span class="line"><span class="meta">        exit(1);                                                 \</span></span><br><span class="line"><span class="meta">    &#125; while (0)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> F&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">cudaTiming</span><span class="params">(<span class="type">const</span> F &amp;func)</span> </span>&#123;</span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">    <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="type">float</span> elapsed_time;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;elapsed_time, start, stop));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;CUDA Time = %g ms.\n&quot;</span>, elapsed_time);</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(start));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(stop));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> F&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">hostTiming</span><span class="params">(<span class="type">const</span> F &amp;func)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> start = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">func</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> end = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line">    std::chrono::duration&lt;<span class="type">double</span>, std::milli&gt; duration = end - start;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Host Time = %g ms.\n&quot;</span>, duration.<span class="built_in">count</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="精度控制模板"><a href="#精度控制模板" class="headerlink" title="精度控制模板"></a>精度控制模板</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// real.hpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_DOUBLE</span></span><br><span class="line"><span class="keyword">using</span> real = <span class="type">double</span>;</span><br><span class="line"><span class="keyword">constexpr</span> real EPS = <span class="number">1e-15</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="keyword">using</span> real = <span class="type">float</span>;</span><br><span class="line"><span class="keyword">constexpr</span> real EPS = <span class="number">1e-6</span>f;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div></div>
  <button>
    Donate
  </button>
  <div class="post-reward">
      <div>
        <img src="/uploads/weixin.png" alt="等疾风 WeChat Pay">
        <span>WeChat Pay</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/GPGPU/" rel="tag"><i class="fa fa-tag"></i> GPGPU</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/05/03/C/" rel="prev" title="C++ 标准笔记">
                  <i class="fa fa-chevron-left"></i> C++ 标准笔记
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/11/08/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/" rel="next" title="网络编程实战">
                  网络编程实战 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">邓子烽</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"Codesire-Deng","repo":"Gitment-for-Codesire-Deng-s-Blog","client_id":"00a098064772784393ca","client_secret":"12657ee4c728b23deac323ac5253a6eb84b4c0a9","admin_user":"Codesire-Deng","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"en","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"c7cea0a899582faa81f3348037f31991"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
